# MSc-Project

Developed a real-time driver distraction detection system as part of the MSc final project, addressing the critical issue of road safety. The system utilizes machine learning techniques, integrating YOLOv8 and CNN EfficientNet models to identify and classify distracted driving behaviors. Designed for affordability and scalability, the system is implemented on a Raspberry Pi with an attached camera, enabling real-time monitoring in in-vehicle environments.
The project included the following key components:
•	Data Preparation and Preprocessing: Leveraged a publicly available dataset for training the machine learning models, incorporating advanced preprocessing techniques like face detection, image augmentation, and resizing using OpenCV.
•	Model Design and Implementation: Combined YOLOv8 for object detection and CNN EfficientNet for feature extraction, ensuring high accuracy and computational efficiency.
•	Hardware Integration: Configured a Raspberry Pi with a camera module to process real-time video streams and detect distracted behaviors under hardware constraints.
•	Testing and Evaluation: Conducted extensive testing under varying environmental conditions (e.g., lighting, motion, and obstructions) to evaluate system performance. Key metrics such as accuracy, latency, and computational efficiency were analyzed.
•	Results and Impact: Delivered a cost-effective, scalable solution capable of detecting distracted behaviors in real time, with potential applications in personal vehicles, fleet management, and road safety systems.
Key Achievements:
•	Designed and implemented a low-cost, resource-efficient solution tailored for real-world use in in-vehicle environments.
•	Addressed the research gap in live detection systems by creating a system capable of real-time operation on hardware-constrained platforms.
•	Gained expertise in machine learning frameworks, including YOLOv8, EfficientNet, and OpenCV, as well as hardware-software integration with Raspberry Pi.
